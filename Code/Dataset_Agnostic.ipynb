{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_GFr_Kj1Hhi",
        "outputId": "10ad25f2-7428-4ad6-b452-7d02da916c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuSFdWg4QG_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350c3177-9c28-476d-81f8-89a4d559e122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (22640, 210) (22640,)\n"
          ]
        }
      ],
      "source": [
        "import datetime as dt\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "path = '/content/drive/MyDrive/3rd Sem/Thesis-Cloud/Latency_Word/Dataset_Agnostic/' + 'df_latency_word(SBU_Proposed).pkl'\n",
        "\n",
        "df_final  = pd.read_pickle(path)\n",
        "df=df_final.copy()\n",
        "\n",
        "# Extract features and target\n",
        "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = df.iloc[:, -1]   # Target (last column)\n",
        "\n",
        "X_train = X\n",
        "y_train = y\n",
        "print(\"Train data shape: \", X_train.shape, y_train.shape)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.3,random_state =123, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/3rd Sem/Thesis-Cloud/Latency_Word/Dataset_Agnostic/' + 'df_latency_word(Buffalo).pkl'\n",
        "df_test = pd.read_pickle(path)\n",
        "\n",
        "X_test = df_test.iloc[:, :-1]\n",
        "y_test = df_test.iloc[:, -1]\n",
        "print(\"Test data shape: \", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGGgEQ-UAptl",
        "outputId": "52ca6da7-f1f1-4798-c3d6-565d55c6dc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data shape:  (14847, 210) (14847,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG31cfSzLFrF"
      },
      "source": [
        "# LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_now = dt.datetime.now()\n",
        "print(ts_now)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eg6TZPQ5uUP",
        "outputId": "62d310ab-9331-478c-ce25-ce22ded4d6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-14 21:03:05.836430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsDkF_OmP9cZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = path = '/content/drive/MyDrive/3rd Sem/Thesis-Cloud/Latency_Word/Dataset_Agnostic/'"
      ],
      "metadata": {
        "id": "Ay1VkFdSa0lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk6UJ4ylPviR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e1d825-ca4b-42ef-8ee5-51bf05bfabde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "[LightGBM] [Info] Number of positive: 9748, number of negative: 12892\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053516 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 39338\n",
            "[LightGBM] [Info] Number of data points in the train set: 22640, number of used features: 180\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430565 -> initscore=-0.279545\n",
            "[LightGBM] [Info] Start training from score -0.279545\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Best Parameters:  {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'num_leaves': 50}\n",
            "Best Estimator Accuracy:  0.8523851590106007\n",
            "Best model saved to /content/drive/MyDrive/3rd Sem/Thesis-Cloud/Latency_Word/Dataset_Agnostic/SBU_Proposed_Dataset_LGBM_Classifier.pkl\n",
            "\n",
            "\n",
            "Accuracy: 0.719876069239577\n",
            "F1 Score: 0.7574219889180519\n",
            "591 FRR:  0.12348516506477225\n",
            "3568 FAR:  0.35463671603220354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35463671603220354, 0.12348516506477225)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'num_leaves': [31, 50, 100],\n",
        "    'boosting_type': ['gbdt', 'dart', 'goss']\n",
        "}\n",
        "\n",
        "# Create LGBMClassifier instance\n",
        "lgbm = LGBMClassifier()\n",
        "\n",
        "# Initialize GridSearchCV with n_jobs=-1 to use all available cores\n",
        "grid_search_lgbm = GridSearchCV(lgbm, param_grid, refit=True, verbose=2, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search_lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Best parameter after tuning\n",
        "print(\"Best Parameters: \", grid_search_lgbm.best_params_)\n",
        "\n",
        "# Model Performance\n",
        "print(\"Best Estimator Accuracy: \", grid_search_lgbm.best_score_)\n",
        "\n",
        "best_model_filename = model_path+'SBU_Proposed_Dataset_LGBM_Classifier.pkl'\n",
        "\n",
        "with open(best_model_filename, 'wb') as file:\n",
        "    pickle.dump(grid_search_lgbm.best_estimator_, file)\n",
        "\n",
        "print(f\"Best model saved to {best_model_filename}\")\n",
        "print()\n",
        "\n",
        "# To make predictions with the saved model, load it from the disk:\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = grid_search_lgbm.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "print()\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Calculate F1 score\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "def calculate_FAR_FRR(y_true, y_pred):\n",
        "    # Calculate confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    # Calculate FAR and FRR\n",
        "    FRR = fp / (fp + tn)\n",
        "    FAR = fn / (fn + tp)\n",
        "\n",
        "    print(fp, \"FRR: \", FRR)\n",
        "    print(fn, \"FAR: \", FAR)\n",
        "\n",
        "    return FAR, FRR\n",
        "\n",
        "calculate_FAR_FRR(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_now = dt.datetime.now()\n",
        "print(ts_now)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFNd8grD5sU4",
        "outputId": "f2c8d693-1ee5-4d1d-db2e-637bfb5406bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-14 22:55:44.439719\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}