{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "def calculate_lexical_density(sentence):\n",
    "    \"\"\"\n",
    "    Calculate lexical density as the ratio of content words to total words.\n",
    "    \"\"\"\n",
    "    content_words = {\"NN\", \"VB\", \"JJ\", \"RB\"}  # Nouns, verbs, adjectives, adverbs\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    content_word_count = sum(1 for word, pos in tagged_tokens if pos[:2] in content_words)\n",
    "    return content_word_count / len(tokens) if tokens else 0\n",
    "\n",
    "def sliding_window_partition(events, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Partition keyboard events into overlapping sliding windows.\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    for start in range(0, len(events) - window_size + 1, step_size):\n",
    "        windows.append(events[start:start + window_size])\n",
    "    return windows\n",
    "\n",
    "def preprocess_llm_free_to_buffalo_format(file_path, window_size=500, step_size=100):\n",
    "    \"\"\"\n",
    "    Preprocess LLM-free data into a Buffalo-like format with sliding windows.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    processed_data = []\n",
    "    english_words = set(words.words())\n",
    "    ignored_keys = {\"Ctrl\", \"Alt\", \"Enter\", \"Tab\"}  # Keys to ignore in sentences\n",
    "\n",
    "    for user_id, actions in data.items():\n",
    "        keyboard_data = actions.get(\"keyboard_data\", [])\n",
    "        windows = sliding_window_partition(keyboard_data, window_size, step_size)\n",
    "\n",
    "        user_entry = {\n",
    "            \"user\": user_id,\n",
    "            \"mode\": 1,  # Mode information unavailable, default to 1\n",
    "            \"Number_of_windows\": len(windows),\n",
    "            \"window_features\": {}\n",
    "        }\n",
    "\n",
    "        for i, window in enumerate(windows):\n",
    "            sentences = []\n",
    "            shift_active = False  # Track if Shift is active\n",
    "            word_speeds = []\n",
    "            kht_dict = {}  # Key Hold Times as a dict\n",
    "            kit_dict = {}  # Key Interval Times as a dict\n",
    "            pause_durations = []\n",
    "            start_time = None\n",
    "            last_key_time = None\n",
    "            last_key = None\n",
    "            spelling_mistakes = 0\n",
    "            word_count = 0\n",
    "            pause_count = 0\n",
    "            total_key_hold_time = 0\n",
    "            backspace_count = 0\n",
    "\n",
    "            current_word_start = None  # Track start time of the current word\n",
    "\n",
    "            for action in window:\n",
    "                action_type, key, timestamp, *_ = action\n",
    "\n",
    "                # Key Hold Time (KHT)\n",
    "                if action_type == \"KD\" and key not in ignored_keys:\n",
    "                    if start_time is None:\n",
    "                        start_time = timestamp  # Capture key-down time\n",
    "                elif action_type == \"KU\" and start_time is not None:\n",
    "                    key_hold_time = (timestamp - start_time) / 1000.0  # Key hold time in seconds\n",
    "                    kht_dict.setdefault(key, []).append(key_hold_time)\n",
    "                    total_key_hold_time += key_hold_time\n",
    "                    start_time = None\n",
    "\n",
    "                # Key Interval Time (KIT)\n",
    "                if action_type == \"KD\" and last_key_time is not None and key not in ignored_keys:\n",
    "                    key_interval = (timestamp - last_key_time) / 1000.0\n",
    "                    if last_key not in ignored_keys:\n",
    "                        kit_key = f\"{last_key}->{key}\"\n",
    "                        kit_dict.setdefault(kit_key, []).append(key_interval)\n",
    "                if action_type == \"KD\":\n",
    "                    last_key_time = timestamp\n",
    "                    last_key = key\n",
    "\n",
    "                # Handle Shift Key\n",
    "                if action_type == \"KD\" and key == \"Shift\":\n",
    "                    shift_active = True\n",
    "                    continue\n",
    "                if action_type == \"KU\" and key == \"Shift\":\n",
    "                    shift_active = False\n",
    "                    continue\n",
    "\n",
    "                # Handle Backspace\n",
    "                if action_type == \"KD\" and key == \"Backspace\":\n",
    "                    backspace_count += 1\n",
    "                    if sentences:  # Remove last character if sentence is not empty\n",
    "                        sentences.pop()\n",
    "                    continue\n",
    "\n",
    "                # Word construction and speed calculation\n",
    "                if action_type == \"KD\" and key.isalnum() and key not in ignored_keys:\n",
    "                    if current_word_start is None:\n",
    "                        current_word_start = timestamp\n",
    "                elif key == \" \" and current_word_start is not None:\n",
    "                    word_duration = (timestamp - current_word_start) / 1000.0\n",
    "                    word_speeds.append(word_duration)\n",
    "                    current_word_start = None  # Reset for the next word\n",
    "\n",
    "                # Sentence construction with Shift handling\n",
    "                if action_type == \"KD\" and key.isprintable() and key not in ignored_keys:\n",
    "                    if shift_active and key.isalpha():\n",
    "                        sentences.append(key.upper())  # Capitalize if Shift is active\n",
    "                    else:\n",
    "                        sentences.append(key)\n",
    "\n",
    "                # Spelling mistakes\n",
    "                if key.isalnum() and key.lower() not in english_words:\n",
    "                    spelling_mistakes += 1\n",
    "\n",
    "            # Finalize features for the window\n",
    "            sentence_text = ''.join(sentences)\n",
    "            word_count = len(re.findall(r'\\b\\w+\\b', sentence_text))\n",
    "            lexical_density = calculate_lexical_density(sentence_text)\n",
    "            average_word_length = sum(len(w) for w in re.findall(r'\\b\\w+\\b', sentence_text)) / word_count if word_count else 0\n",
    "\n",
    "            user_entry[\"window_features\"][f\"window_{i + 1}\"] = {\n",
    "                \"sentence_number\": i + 1,\n",
    "                \"sentence\": sentence_text,\n",
    "                \"word_wise_speed\": word_speeds,\n",
    "                \"key_hold_times\": kht_dict,  # Dictionary of KHT\n",
    "                \"key_interval_times\": kit_dict,  # Dictionary of KIT\n",
    "                \"number_of_words\": word_count,\n",
    "                \"pause_list_sentence\": pause_durations,\n",
    "                \"backspace_count_sentence\": backspace_count,\n",
    "                \"average_word_length\": average_word_length,\n",
    "                \"duration_between_pauses_sentence\": pause_durations,\n",
    "                \"characters_before_first_pause\": sum(1 for c in sentence_text if c != \" \") if pause_count > 0 else 0,\n",
    "                \"words_before_first_pause\": len(re.findall(r'\\b\\w+\\b', sentence_text)) if pause_count > 0 else 0,\n",
    "                \"nouns_per_sentence\": sum(1 for word, pos in pos_tag(word_tokenize(sentence_text)) if pos.startswith(\"NN\")),\n",
    "                \"verbs_per_sentence\": sum(1 for word, pos in pos_tag(word_tokenize(sentence_text)) if pos.startswith(\"VB\")),\n",
    "                \"modifiers_per_sentence\": sum(1 for word, pos in pos_tag(word_tokenize(sentence_text)) if pos in {\"JJ\", \"RB\"}),\n",
    "                \"modals_per_sentence\": sum(1 for word, pos in pos_tag(word_tokenize(sentence_text)) if pos == \"MD\"),\n",
    "                \"lexical_density_of_the_sentence\": lexical_density,\n",
    "                \"number_of_spelling_mistakes\": spelling_mistakes,\n",
    "                \"number_of_special_characters_sentence\": sum(not c.isalnum() for c in sentence_text),\n",
    "                \"number_of_printable_characters\": len(sentence_text),\n",
    "                \"keystrokes_per_burst\": total_key_hold_time,\n",
    "                \"pause_durations\": pause_durations,\n",
    "                \"long_pauses\": sum(1 for p in pause_durations if p > 1.0),  # Pauses longer than 1 second\n",
    "            }\n",
    "\n",
    "        processed_data.append(user_entry)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "# File path\n",
    "llm_file = \"/content/drive/MyDrive/Thesis-Cloud/Atharva/StonyBrook_json_format/Raw_Temp/Raw_Temp_Gay_Marriage_Fixed.json\"\n",
    "\n",
    "# Preprocess data to Buffalo-like format\n",
    "llm_free_buffalo_format = preprocess_llm_free_to_buffalo_format(llm_file, window_size=1000, step_size=300)\n",
    "\n",
    "# Save processed data\n",
    "output_file = \"processed_llm_free_buffalo_format_shift_backspace.json\"\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(llm_free_buffalo_format, file, indent=4)\n",
    "\n",
    "print(f\"Buffalo-like format preprocessing complete. File saved as {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
